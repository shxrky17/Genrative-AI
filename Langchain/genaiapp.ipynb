{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "os.environ['LANGCHAIN_API_KEY']=os.getenv(\"LANGCHAIN_API_KEY\")\n",
    "\n",
    "os.environ['LANGCHAIN_project']=os.getenv(\"LANGCHAIN_project\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chafl\\miniconda3\\envs\\hello\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "genai.GenerativeModel(\n",
      "    model_name='models/gemini-1.5-flash',\n",
      "    generation_config={},\n",
      "    safety_settings={},\n",
      "    tools=None,\n",
      "    system_instruction=None,\n",
      "    cached_content=None\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import google.generativeai as genai\n",
    "\n",
    "key=os.environ['GEMINI_API_KEY']=os.getenv(\"GEMINI_API_KEY\")\n",
    "genai.configure(api_key=key)\n",
    "model = genai.GenerativeModel(\"gemini-1.5-flash\")\n",
    "response = model.generate_content(\"Explain how AI works\")\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import WebBaseLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader=WebBaseLoader(\"https://docs.smith.langchain.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langchain_community.document_loaders.web_base.WebBaseLoader at 0x212158f78f0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'https://docs.smith.langchain.com/', 'title': 'Get started with LangSmith | ü¶úÔ∏èüõ†Ô∏è LangSmith', 'description': 'LangSmith is a platform for building production-grade LLM applications.', 'language': 'en'}, page_content='\\n\\n\\n\\n\\nGet started with LangSmith | ü¶úÔ∏èüõ†Ô∏è LangSmith\\n\\n\\n\\n\\n\\n\\nSkip to main contentLearn the essentials of LangSmith in the new Introduction to LangSmith course!  Enroll for free. API ReferenceRESTPythonSearchRegionUSEUGo to AppQuick StartObservabilityEvaluationPrompt EngineeringDeployment (LangGraph Platform)AdministrationSelf-hostingPricingReferenceCloud architecture and scalabilityAuthz and AuthnAuthentication methodsdata_formatsEvaluationDataset transformationsRegions FAQsdk_referenceQuick StartOn this pageGet started with LangSmith\\nLangSmith is a platform for building production-grade LLM applications.\\nIt allows you to closely monitor and evaluate your application, so you can ship quickly and with confidence.\\nWith LangSmith you can:\\n\\nTrace LLM Applications: Gain visibility into LLM calls and other parts of your application\\'s logic.\\nEvaluate Performance: Compare results across models, prompts, and architectures to identify what works best.\\nImprove Prompts: Quickly refine prompts to achieve more accurate and reliable results.\\n\\nLangSmith + LangChain OSSLangSmith integrates seamlessly with LangChain\\'s open source frameworks langchain and langgraph, with no extra instrumentation needed.If you\\'re already using either of these, see the how-to guide for setting up LangSmith with LangChain or setting up LangSmith with LangGraph.\\nLangSmith is a standalone platform that can be used on it\\'s own no matter how you\\'re creating your LLM applicatons.\\nIn this tutorial, we\\'ll walk you though logging your first trace in LangSmith using the LangSmith SDK and running an evaluation to measure the performance of your application. This example uses the OpenAI API, however you can use your provider of choice.\\n1. Install LangSmith\\u200b\\nPythonTypeScriptpip install -U langsmith openaiyarn add langsmith openai\\n2. Create an API key\\u200b\\nTo create an API key head to the Settings page. Then click Create API Key.\\n3. Set up your environment\\u200b\\nShellexport LANGCHAIN_TRACING_V2=trueexport LANGCHAIN_API_KEY=<your-api-key>export OPENAI_API_KEY=<your-openai-api-key>\\n4. Log your first trace\\u200b\\nWe provide multiple ways to log traces to LangSmith. Below, we\\'ll highlight\\nhow to use traceable(). See more on the Annotate code for tracing page.\\nPythonTypeScriptimport openaifrom langsmith import wrappers, traceable# Auto-trace LLM calls in-contextclient = wrappers.wrap_openai(openai.Client())@traceable # Auto-trace this functiondef pipeline(user_input: str):    result = client.chat.completions.create(        messages=[{\"role\": \"user\", \"content\": user_input}],        model=\"gpt-4o-mini\"    )    return result.choices[0].message.contentpipeline(\"Hello, world!\")# Out:  Hello there! How can I assist you today?import { OpenAI } from \"openai\";import { traceable } from \"langsmith/traceable\";import { wrapOpenAI } from \"langsmith/wrappers\";// Auto-trace LLM calls in-contextconst client = wrapOpenAI(new OpenAI());// Auto-trace this functionconst pipeline = traceable(async (user_input) => {    const result = await client.chat.completions.create({        messages: [{ role: \"user\", content: user_input }],        model: \"gpt-4o-mini\",    });    return result.choices[0].message.content;});await pipeline(\"Hello, world!\")// Out: Hello there! How can I assist you today?\\nLearn more about tracing in the observability tutorials, conceptual guide and how-to guides.\\n5. View your trace\\u200b\\nBy default, the trace will be logged to the project with the name default. You should see the following sample output trace logged using the above code.\\n6. Run your first evaluation\\u200b\\nEvaluations help assess application performance by testing the application against a given set of inputs. Evaluations require a system to test, data to serve as test cases, and evaluators to grade the results.\\nHere we are running an evaluation against a sample dataset using a simple custom evaluator that checks if the real output exactly matches our gold-standard output.\\nPythonTypeScriptfrom langsmith import Client, traceableclient = Client()# Define dataset: these are your test casesdataset = client.create_dataset(    \"Sample Dataset\",    description=\"A sample dataset in LangSmith.\",)client.create_examples(    inputs=[        {\"postfix\": \"to LangSmith\"},        {\"postfix\": \"to Evaluations in LangSmith\"},    ],    outputs=[        {\"response\": \"Welcome to LangSmith\"},        {\"response\": \"Welcome to Evaluations in LangSmith\"},    ],    dataset_id=dataset.id,)# Define an interface to your application (tracing optional)@traceabledef dummy_app(inputs: dict) -> dict:    return {\"response\": \"Welcome \" + inputs[\"postfix\"]}# Define your evaluator(s)def exact_match(outputs: dict, reference_outputs: dict) -> bool:    return outputs[\"response\"] == reference_outputs[\"response\"]# Run the evaluationexperiment_results = client.evaluate(    dummy_app, # Your AI system goes here    data=dataset, # The data to predict and grade over    evaluators=[exact_match], # The evaluators to score the results    experiment_prefix=\"sample-experiment\", # The name of the experiment    metadata={\"version\": \"1.0.0\", \"revision_id\": \"beta\"}, # Metadata about the experiment    max_concurrency=4,  # Add concurrency.)# Analyze the results via the UI or programmatically# If you have \\'pandas\\' installed you can view the results as a# pandas DataFrame by uncommenting below:# experiment_results.to_pandas()import { Client } from \"langsmith\";import { EvaluationResult, evaluate } from \"langsmith/evaluation\";const client = new Client();// Define dataset: these are your test casesconst datasetName = \"Sample Dataset\";const dataset = await client.createDataset(datasetName, {  description: \"A sample dataset in LangSmith.\",});await client.createExamples({  inputs: [    { postfix: \"to LangSmith\" },    { postfix: \"to Evaluations in LangSmith\" },  ],  outputs: [    { response: \"Welcome to LangSmith\" },    { response: \"Welcome to Evaluations in LangSmith\" },  ],  datasetId: dataset.id,});// Define your evaluator(s)const exactMatch = async ({ outputs, referenceOutputs }: {  outputs?: Record<string, any>;  referenceOutputs?: Record<string, any>;}): Promise<EvaulationResult> => {  return {    key: \"exact_match\",    score: outputs?.response === referenceOutputs?.response,  };};// Run the evaluationconst experimentResults = await evaluate(  (inputs: { postfix: string }) => ({ response: `Welcome ${inputs.postfix}` }),  {    data: datasetName,    evaluators: [exactMatch],    metadata: { version: \"1.0.0\", revision_id: \"beta\" },    maxConcurrency: 4,  });\\n\\nClick the link printed out by your evaluation run to access the LangSmith experiments UI,\\nand explore the results of your evaluation.\\nLearn more about evaluation in the tutorials, conceptual guide, and how-to guides.\\nWas this page helpful?You can leave detailed feedback on GitHub.NextConcepts1. Install LangSmith2. Create an API key3. Set up your environment4. Log your first trace5. View your trace6. Run your first evaluationCommunityDiscordTwitterGitHubDocs CodeLangSmith SDKPythonJS/TSMoreHomepageBlogLangChain Python DocsLangChain JS/TS DocsCopyright ¬© 2024 LangChain, Inc.\\n\\n')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs=loader.load()\n",
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "text_splitter=RecursiveCharacterTextSplitter(chunk_size=1000,chunk_overlap=200)\n",
    "documents=text_splitter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'https://docs.smith.langchain.com/', 'title': 'Get started with LangSmith | ü¶úÔ∏èüõ†Ô∏è LangSmith', 'description': 'LangSmith is a platform for building production-grade LLM applications.', 'language': 'en'}, page_content='Get started with LangSmith | ü¶úÔ∏èüõ†Ô∏è LangSmith\\n\\n\\n\\n\\n\\n\\nSkip to main contentLearn the essentials of LangSmith in the new Introduction to LangSmith course!  Enroll for free. API ReferenceRESTPythonSearchRegionUSEUGo to AppQuick StartObservabilityEvaluationPrompt EngineeringDeployment (LangGraph Platform)AdministrationSelf-hostingPricingReferenceCloud architecture and scalabilityAuthz and AuthnAuthentication methodsdata_formatsEvaluationDataset transformationsRegions FAQsdk_referenceQuick StartOn this pageGet started with LangSmith\\nLangSmith is a platform for building production-grade LLM applications.\\nIt allows you to closely monitor and evaluate your application, so you can ship quickly and with confidence.\\nWith LangSmith you can:'),\n",
       " Document(metadata={'source': 'https://docs.smith.langchain.com/', 'title': 'Get started with LangSmith | ü¶úÔ∏èüõ†Ô∏è LangSmith', 'description': 'LangSmith is a platform for building production-grade LLM applications.', 'language': 'en'}, page_content=\"Trace LLM Applications: Gain visibility into LLM calls and other parts of your application's logic.\\nEvaluate Performance: Compare results across models, prompts, and architectures to identify what works best.\\nImprove Prompts: Quickly refine prompts to achieve more accurate and reliable results.\"),\n",
       " Document(metadata={'source': 'https://docs.smith.langchain.com/', 'title': 'Get started with LangSmith | ü¶úÔ∏èüõ†Ô∏è LangSmith', 'description': 'LangSmith is a platform for building production-grade LLM applications.', 'language': 'en'}, page_content=\"LangSmith + LangChain OSSLangSmith integrates seamlessly with LangChain's open source frameworks langchain and langgraph, with no extra instrumentation needed.If you're already using either of these, see the how-to guide for setting up LangSmith with LangChain or setting up LangSmith with LangGraph.\\nLangSmith is a standalone platform that can be used on it's own no matter how you're creating your LLM applicatons.\\nIn this tutorial, we'll walk you though logging your first trace in LangSmith using the LangSmith SDK and running an evaluation to measure the performance of your application. This example uses the OpenAI API, however you can use your provider of choice.\\n1. Install LangSmith\\u200b\\nPythonTypeScriptpip install -U langsmith openaiyarn add langsmith openai\\n2. Create an API key\\u200b\\nTo create an API key head to the Settings page. Then click Create API Key.\\n3. Set up your environment\\u200b\"),\n",
       " Document(metadata={'source': 'https://docs.smith.langchain.com/', 'title': 'Get started with LangSmith | ü¶úÔ∏èüõ†Ô∏è LangSmith', 'description': 'LangSmith is a platform for building production-grade LLM applications.', 'language': 'en'}, page_content=\"PythonTypeScriptpip install -U langsmith openaiyarn add langsmith openai\\n2. Create an API key\\u200b\\nTo create an API key head to the Settings page. Then click Create API Key.\\n3. Set up your environment\\u200b\\nShellexport LANGCHAIN_TRACING_V2=trueexport LANGCHAIN_API_KEY=<your-api-key>export OPENAI_API_KEY=<your-openai-api-key>\\n4. Log your first trace\\u200b\\nWe provide multiple ways to log traces to LangSmith. Below, we'll highlight\\nhow to use traceable(). See more on the Annotate code for tracing page.\"),\n",
       " Document(metadata={'source': 'https://docs.smith.langchain.com/', 'title': 'Get started with LangSmith | ü¶úÔ∏èüõ†Ô∏è LangSmith', 'description': 'LangSmith is a platform for building production-grade LLM applications.', 'language': 'en'}, page_content='PythonTypeScriptimport openaifrom langsmith import wrappers, traceable# Auto-trace LLM calls in-contextclient = wrappers.wrap_openai(openai.Client())@traceable # Auto-trace this functiondef pipeline(user_input: str):    result = client.chat.completions.create(        messages=[{\"role\": \"user\", \"content\": user_input}],        model=\"gpt-4o-mini\"    )    return result.choices[0].message.contentpipeline(\"Hello, world!\")# Out:  Hello there! How can I assist you today?import { OpenAI } from \"openai\";import { traceable } from \"langsmith/traceable\";import { wrapOpenAI } from \"langsmith/wrappers\";// Auto-trace LLM calls in-contextconst client = wrapOpenAI(new OpenAI());// Auto-trace this functionconst pipeline = traceable(async (user_input) => {    const result = await client.chat.completions.create({        messages: [{ role: \"user\", content: user_input }],        model: \"gpt-4o-mini\",    });    return result.choices[0].message.content;});await pipeline(\"Hello, world!\")// Out: Hello there!'),\n",
       " Document(metadata={'source': 'https://docs.smith.langchain.com/', 'title': 'Get started with LangSmith | ü¶úÔ∏èüõ†Ô∏è LangSmith', 'description': 'LangSmith is a platform for building production-grade LLM applications.', 'language': 'en'}, page_content='messages: [{ role: \"user\", content: user_input }],        model: \"gpt-4o-mini\",    });    return result.choices[0].message.content;});await pipeline(\"Hello, world!\")// Out: Hello there! How can I assist you today?'),\n",
       " Document(metadata={'source': 'https://docs.smith.langchain.com/', 'title': 'Get started with LangSmith | ü¶úÔ∏èüõ†Ô∏è LangSmith', 'description': 'LangSmith is a platform for building production-grade LLM applications.', 'language': 'en'}, page_content='Learn more about tracing in the observability tutorials, conceptual guide and how-to guides.\\n5. View your trace\\u200b\\nBy default, the trace will be logged to the project with the name default. You should see the following sample output trace logged using the above code.\\n6. Run your first evaluation\\u200b\\nEvaluations help assess application performance by testing the application against a given set of inputs. Evaluations require a system to test, data to serve as test cases, and evaluators to grade the results.\\nHere we are running an evaluation against a sample dataset using a simple custom evaluator that checks if the real output exactly matches our gold-standard output.'),\n",
       " Document(metadata={'source': 'https://docs.smith.langchain.com/', 'title': 'Get started with LangSmith | ü¶úÔ∏èüõ†Ô∏è LangSmith', 'description': 'LangSmith is a platform for building production-grade LLM applications.', 'language': 'en'}, page_content='PythonTypeScriptfrom langsmith import Client, traceableclient = Client()# Define dataset: these are your test casesdataset = client.create_dataset(    \"Sample Dataset\",    description=\"A sample dataset in LangSmith.\",)client.create_examples(    inputs=[        {\"postfix\": \"to LangSmith\"},        {\"postfix\": \"to Evaluations in LangSmith\"},    ],    outputs=[        {\"response\": \"Welcome to LangSmith\"},        {\"response\": \"Welcome to Evaluations in LangSmith\"},    ],    dataset_id=dataset.id,)# Define an interface to your application (tracing optional)@traceabledef dummy_app(inputs: dict) -> dict:    return {\"response\": \"Welcome \" + inputs[\"postfix\"]}# Define your evaluator(s)def exact_match(outputs: dict, reference_outputs: dict) -> bool:    return outputs[\"response\"] == reference_outputs[\"response\"]# Run the evaluationexperiment_results = client.evaluate(    dummy_app, # Your AI system goes here    data=dataset, # The data to predict and grade over    evaluators=[exact_match], # The'),\n",
       " Document(metadata={'source': 'https://docs.smith.langchain.com/', 'title': 'Get started with LangSmith | ü¶úÔ∏èüõ†Ô∏è LangSmith', 'description': 'LangSmith is a platform for building production-grade LLM applications.', 'language': 'en'}, page_content='Run the evaluationexperiment_results = client.evaluate(    dummy_app, # Your AI system goes here    data=dataset, # The data to predict and grade over    evaluators=[exact_match], # The evaluators to score the results    experiment_prefix=\"sample-experiment\", # The name of the experiment    metadata={\"version\": \"1.0.0\", \"revision_id\": \"beta\"}, # Metadata about the experiment    max_concurrency=4,  # Add concurrency.)# Analyze the results via the UI or programmatically# If you have \\'pandas\\' installed you can view the results as a# pandas DataFrame by uncommenting below:# experiment_results.to_pandas()import { Client } from \"langsmith\";import { EvaluationResult, evaluate } from \"langsmith/evaluation\";const client = new Client();// Define dataset: these are your test casesconst datasetName = \"Sample Dataset\";const dataset = await client.createDataset(datasetName, {  description: \"A sample dataset in LangSmith.\",});await client.createExamples({  inputs: [    { postfix: \"to LangSmith\" },'),\n",
       " Document(metadata={'source': 'https://docs.smith.langchain.com/', 'title': 'Get started with LangSmith | ü¶úÔ∏èüõ†Ô∏è LangSmith', 'description': 'LangSmith is a platform for building production-grade LLM applications.', 'language': 'en'}, page_content='\"Sample Dataset\";const dataset = await client.createDataset(datasetName, {  description: \"A sample dataset in LangSmith.\",});await client.createExamples({  inputs: [    { postfix: \"to LangSmith\" },    { postfix: \"to Evaluations in LangSmith\" },  ],  outputs: [    { response: \"Welcome to LangSmith\" },    { response: \"Welcome to Evaluations in LangSmith\" },  ],  datasetId: dataset.id,});// Define your evaluator(s)const exactMatch = async ({ outputs, referenceOutputs }: {  outputs?: Record<string, any>;  referenceOutputs?: Record<string, any>;}): Promise<EvaulationResult> => {  return {    key: \"exact_match\",    score: outputs?.response === referenceOutputs?.response,  };};// Run the evaluationconst experimentResults = await evaluate(  (inputs: { postfix: string }) => ({ response: `Welcome ${inputs.postfix}` }),  {    data: datasetName,    evaluators: [exactMatch],    metadata: { version: \"1.0.0\", revision_id: \"beta\" },    maxConcurrency: 4,  });'),\n",
       " Document(metadata={'source': 'https://docs.smith.langchain.com/', 'title': 'Get started with LangSmith | ü¶úÔ∏èüõ†Ô∏è LangSmith', 'description': 'LangSmith is a platform for building production-grade LLM applications.', 'language': 'en'}, page_content='Click the link printed out by your evaluation run to access the LangSmith experiments UI,\\nand explore the results of your evaluation.\\nLearn more about evaluation in the tutorials, conceptual guide, and how-to guides.\\nWas this page helpful?You can leave detailed feedback on GitHub.NextConcepts1. Install LangSmith2. Create an API key3. Set up your environment4. Log your first trace5. View your trace6. Run your first evaluationCommunityDiscordTwitterGitHubDocs CodeLangSmith SDKPythonJS/TSMoreHomepageBlogLangChain Python DocsLangChain JS/TS DocsCopyright ¬© 2024 LangChain, Inc.')]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.042016264, 0.007864275, -0.07740791, 8.5567335e-05, 0.03354253, 0.03493411, 0.10052096, -0.0042228303, -0.013642928, 0.00029817398, 0.0072805667, 0.028487252, -0.004554776, 0.018560672, 0.00437506, -0.02873504, 0.002690923, 0.043193102, -0.066394195, 0.004035266, -0.026072117, -0.01573005, -0.034026705, -0.05121902, -0.026877217, -0.049202207, 0.026218347, 0.024586778, 0.011199548, -0.020560157, 0.035028268, -0.009070159, 0.022588037, -0.02412822, -0.0046472745, 0.04652012, 0.020839514, -0.004098031, 0.021439552, -0.045893986, -0.012233917, 0.0150002865, -0.06283724, 0.113400415, -0.001672235, -0.06492364, -0.016687926, 0.011639574, -0.031694934, 0.026598807, 0.08006429, -0.033575635, -0.06608389, 0.02408414, -0.013405745, -0.030586066, -0.021699617, -0.020542774, 0.011593918, 0.02218874, -0.0073657744, -0.045084003, 0.0018586115, 0.005312839, 0.003729045, -0.007630019, -0.032453746, -0.03446561, -0.015009115, 0.022695739, -0.0006228825, 0.005656795, -0.02598856, 0.03398705, -0.035836697, 0.021943519, -0.025154127, -0.030647362, 0.023275303, 0.03803533, -0.03051154, -0.0040174467, 0.049570296, 0.0057474766, 0.050982244, -0.025566673, -0.011016899, -0.07720049, -0.05147399, -0.0084427, 0.09233842, 0.009023363, -0.0029159687, 0.0083658425, 0.04468593, -0.04904471, -0.102534, -0.10791461, 0.030697644, 0.08001567, -0.051781308, 0.046179462, 0.004323191, -0.05175883, 0.0050742244, 0.032045923, -0.020077737, -0.052330565, -0.10492805, 0.030471044, 0.023455068, 0.0720999, 0.021871679, -0.03350013, -0.045304116, -0.02694303, 0.022851322, 0.029411009, -0.019991886, -0.010741749, -0.00013358607, 0.054897893, -0.00761017, 0.061683606, 0.032775186, 0.04956625, 0.043070763, 0.0097147245, -0.09264603, -0.020430038, 0.094493106, -0.06539882, -0.013448295, -0.018954232, -0.017522916, -0.009606616, 0.089752644, -0.04406146, -0.021832397, 0.054138754, -0.015634537, -0.018328644, -0.056899127, 0.009365128, -0.005112851, -0.056270875, 0.034474738, 0.1022498, 0.04927013, 0.017719116, -0.025567891, 0.010181449, 0.023730153, 0.020729113, -0.042924248, 0.011220993, -0.023640722, -0.0470085, 0.04269518, 0.017018631, 0.029465394, -0.077321246, 0.002352599, 0.06815275, -0.02795424, -0.04201616, 0.016302316, -0.082273245, 0.03881652, -0.015548704, -0.020534532, 0.040838245, -0.046631385, -0.058806192, 0.013502929, 0.030925425, -3.414523e-05, -0.059840385, -0.06651574, -0.07007906, 0.103850685, 0.016216373, 0.028434118, -0.06895897, -0.014368988, -0.009180165, -0.082806446, -0.0014597961, 0.034291804, 0.1162811, -0.036284175, 0.015114694, 0.050786458, 0.006580709, -0.015531319, 0.025737083, 0.04029358, -0.040299304, 0.017919553, -0.018242516, 0.02750502, -0.0011893273, 0.008886345, -0.033190433, -0.02174474, -0.007615652, 0.0020139187, -0.03148103, 0.0038939735, 0.03253585, -0.037261046, -0.029606331, -0.0060352855, -0.045929752, -0.008348128, 0.010161172, 0.04133657, 0.001199205, 0.034912024, -0.013138243, -0.00075718894, -0.03905843, -0.004595316, 0.024065493, 0.06450039, 0.03510897, -0.0070959213, 0.01981853, -0.0044319225, -0.046668775, -0.013070415, 0.020714222, 0.008220295, 0.06452754, 0.0027210885, 0.06461048, 0.0133666, -0.02735318, -0.020443182, 0.0031174577, -0.006971414, 0.030043315, -0.030447068, -0.017635193, 0.060074817, 0.018064966, 0.026794827, 0.06364081, 0.015350341, 0.0011295592, 0.0063483836, 0.010156436, -0.051552586, 0.028615756, 0.0063345893, 0.0399037, 0.05345727, 0.00030772033, -0.02741811, -0.010830083, 0.06367128, -0.025872486, 0.0072256634, -0.05262215, -0.005164154, -0.062572666, -0.013191868, -0.019629935, 0.036138583, -0.051745087, 0.029226687, -0.043668523, -0.039060026, -0.045110382, -0.0077488334, 0.026670724, -0.03400386, -0.010674801, -0.050480668, -0.06351746, 0.0022228006, 0.013885803, 0.018986162, 0.027152823, 0.010158874, -0.057903577, 0.019359313, 0.022323104, -0.02437359, -0.05270249, 0.0975936, 0.01974377, -0.04812374, -0.041056756, -0.044618443, 0.0062990887, 0.051593464, -0.00032359836, 0.014714115, -0.026665278, 0.027327444, 0.039355766, -0.0086322045, 0.11388605, 0.012567949, 0.035556916, 0.018789418, -0.03569285, 0.0033028661, -0.021987878, 0.044187136, 0.010235821, -0.07166206, -0.054613538, -0.02011999, -0.027920399, -0.10186762, -0.030558543, -0.012751259, -0.049594317, 0.045737296, 0.011852165, -0.016662044, -0.035272676, 0.03247642, 0.01906208, -0.0021512099, -0.03080065, 0.021595208, -0.032779038, 0.07677653, 0.0010934636, -0.010168546, -0.057465244, 0.025301758, 0.05412462, -0.053165875, 0.017303469, 0.08587263, -0.00920013, 0.01405737, -0.00409868, 0.048164017, 0.020447632, 0.019262664, 0.009514866, -0.003367936, -0.009123042, -0.017302534, -0.01010757, 0.025621135, 0.027595993, 0.031225242, 0.027807694, -0.01597635, 0.03831922, -0.018339762, 0.01931969, -0.003979839, 0.010385885, -0.0038289607, 0.010407265, -0.007948083, 0.03743851, 0.009322191, 0.0037192483, 0.03078479, 0.021572448, -0.016812058, -0.026568716, 0.027962165, 0.03624594, 0.038650896, -0.001429167, 0.019047294, -0.09669167, -0.03587655, 0.00944283, 0.0047334693, -0.08472358, 0.019897288, -0.023243345, 0.014274586, 0.025579661, 0.0108225085, 0.0031314942, -0.06272133, -0.0068112668, 0.012984924, 0.015486506, -0.039607953, 0.012923005, 0.06661235, 0.035024915, -0.01764716, 0.027276892, -0.052436512, 0.023667566, 0.01618912, 0.00059790694, 0.016825024, 0.0029461856, 0.018654604, -0.014764499, -0.0042657293, 0.025408475, 0.08976398, 0.0222261, 0.0064477245, 0.01686239, -0.04840308, -0.010423764, 0.0065054856, 0.021949131, -0.008582004, -0.014342377, -0.000957893, 0.01404868, -0.03152765, 0.0124678435, 0.031349547, 0.00037873432, 0.03246719, 0.01232289, 0.012504861, -0.07342906, 0.009470204, -0.0022761747, 0.011859582, -0.0021984854, 0.023930674, 0.009062783, 0.007686788, -0.0027102365, -0.048307683, 0.06526647, -0.0076307636, -0.027473005, 0.004745782, -0.0015392142, -0.011823169, -0.015409159, 0.018426979, -0.007253015, -0.043713927, 0.047644515, 0.01034223, 0.047437273, 0.0017019652, -0.06596537, 0.021759273, -0.019965552, 0.031013662, -0.028678644, -0.09939522, 0.028133865, -0.018525966, 0.035472184, -0.011047453, 0.019252218, -0.024448188, -0.025907146, 0.053210933, -0.015458467, -0.03331896, -0.017591357, -0.04483915, -0.013558982, 0.0034702918, 0.04697497, 0.059397496, 0.028694872, 0.06467653, -0.020081762, -0.059405852, 0.054900948, 0.06923956, -0.013840792, 0.005398521, -0.050752133, -0.044531282, 0.030388193, -0.014616632, 0.049929153, 0.039396573, -0.011201869, -0.041457865, 0.052936003, -0.036415685, -0.0019373024, -0.04250768, -0.01899584, 0.003050787, -0.02135111, -0.015325701, -0.007746765, 0.032502588, 0.018224781, 0.059005655, 0.02855395, 0.03976308, 0.016788054, 0.0058795204, 0.0014843357, -0.025196716, -1.7295677e-05, -0.041089024, 0.01138261, 0.09227136, 0.029474864, 0.037444744, -0.042213578, -0.0094390055, -0.026527856, 0.0108864615, 0.032859247, -0.022554668, -0.0058672167, -0.014579622, 0.045294363, -0.040346626, 0.005213066, 0.04503662, 0.0148469005, -0.0085267, -0.041036386, 0.037298407, -0.0074222637, 0.07342729, -0.021152973, 0.016861234, 0.079403, -0.0071108695, 0.009899513, -0.007253061, 0.061167646, -0.008112851, 0.036824487, 0.034949794, -0.0034056047, -0.0054185158, 0.013789532, -0.009692631, 0.016783029, 0.038742863, 0.023315238, 0.02775945, 0.04798385, -0.019671034, 0.05775259, -0.033200555, -0.02272416, -0.01713461, 0.006789752, 0.0021353266, 0.013153513, 0.0027681855, -0.028470786, 0.018189887, 0.025087852, -0.0030626864, -0.025300585, -0.042585876, -0.0044949953, 0.009477407, -0.011060761, -0.019630728, 0.053708684, -0.016164787, -0.014654666, -0.019191148, -0.015629333, -0.049908932, -0.0020206033, 0.018263115, -0.032744136, -0.021132056, 0.016537385, 0.037745185, 0.014454644, 0.0314557, 0.02719757, 0.078199685, 0.008645401, -0.03199762, -0.011664234, 0.015501449, -0.020198822, 0.016386371, -0.021441659, 0.00014219467, 0.0021067734, 0.014878401, -0.045404118, -0.011759719, -0.03776663, -0.0030726788, 0.03056242, 0.03445866, -0.00046138227, 0.009159142, -0.047169022, 0.09319733, -0.012473096, -0.039739173, -0.08846824, -0.01682631, -0.00512352, -0.055710007, -0.019523269, 0.0076330355, 0.030544419, 0.007533976, 0.0017916295, -0.09897545, 0.014861692, -0.016997088, -0.014776915, -0.006051607, -0.015850792, 0.028945968, -0.012322778, 0.007365456, -0.025765056, 0.016638622, -0.03655421, -0.015141782, 0.023615211, 0.06779819, 0.04135944, -0.01891176, -0.016550615, 0.042600572, -0.0008143247, 0.042153824, -0.025256159, -0.011981338, 0.01791101, 0.012062245, -0.04920101, 0.031888627, -0.011052529, 0.053180285, -0.017434262, -0.027656943, -0.011347853, 0.0042457944, -0.03820256, 0.016675744, 0.07933326, 0.014344742, 0.057047844, -0.024461126, 0.050900843, -0.059548642, 0.051185135, -0.050766714, 0.042940583, -0.0027121997, 0.029921398, -0.02087953, -0.024892684, -0.048381228, 0.017689236, -0.041515864, -0.041127846, -0.032674804, 0.005404344, -0.0010188961, -0.018626934, -0.021217242, -0.00774337, 0.029808726, 0.047114838, -0.012586524, 0.03691103, -0.029726867, -0.0006774459, -0.019335333, 0.04139022, -0.011195611, -0.0238864, 0.001619598, 0.0017254008, 0.008270418, -0.007725826, 0.010416626, -0.031441428, 0.009048603, 0.030851364, -0.02556647, -0.01476417, -0.032616258, 0.012980247, -0.021853434, 0.0606613, 0.0092157945, 0.02682081, -0.04618596, -0.027421309, -0.038799368, -0.005729541, -0.035508156, -0.03864229, 0.0072464114, -0.006891378, 0.06762696, 0.044250745, -0.023466524, 0.009386817, -0.0363807, 0.007449716, 0.07036882, -0.022184, -0.038829867, 0.018525405, 0.032533262, 0.016383443, -0.013630294, 0.004382434, 0.017268818, -0.02338981, 0.05382558, 0.051536478, 0.023799261, 0.034214016, -0.009146351, -0.023674987, -0.02473962, 0.012939888, -0.015727315, -0.041273687, -0.06041807, 0.08727628, -0.048303857, -0.01972622, -0.0024004388, -0.014135714, -0.015013818, -0.023649083, 0.04256713, -0.019997371, -0.015464462, -0.021998664, 0.020744568, 0.015239218, 0.009172654, 0.04359574, 0.008391339, -0.022008244, -0.06590892, -0.021185929, -0.00049042585, 0.00021353255, 0.04018418, 0.015084637, -0.00947875, 0.013453709, 0.032464452, -0.020794086, 0.0119317295, 0.05980766, -0.03808156, 0.020804405, -0.01532792, -0.06700011, 0.050246418, 0.029456995]]\n"
     ]
    }
   ],
   "source": [
    "import google.generativeai as genai\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Load the .env file\n",
    "load_dotenv()\n",
    "\n",
    "genai.configure(api_key=key)\n",
    "documents = [str(item) for item in docs if item is not None]\n",
    "result = genai.embed_content(\n",
    "        model=\"models/text-embedding-004\",\n",
    "        content=documents\n",
    "        )\n",
    "\n",
    "res=print(str(result['embedding']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import FAISS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'page_content'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[31], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m vectorstoredb\u001b[38;5;241m=\u001b[39m\u001b[43mFAISS\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_documents\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdocuments\u001b[49m\u001b[43m,\u001b[49m\u001b[43mres\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\chafl\\miniconda3\\envs\\hello\\Lib\\site-packages\\langchain_core\\vectorstores\\base.py:841\u001b[0m, in \u001b[0;36mVectorStore.from_documents\u001b[1;34m(cls, documents, embedding, **kwargs)\u001b[0m\n\u001b[0;32m    824\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[0;32m    825\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfrom_documents\u001b[39m(\n\u001b[0;32m    826\u001b[0m     \u001b[38;5;28mcls\u001b[39m: \u001b[38;5;28mtype\u001b[39m[VST],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    829\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m    830\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m VST:\n\u001b[0;32m    831\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return VectorStore initialized from documents and embeddings.\u001b[39;00m\n\u001b[0;32m    832\u001b[0m \n\u001b[0;32m    833\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    839\u001b[0m \u001b[38;5;124;03m        VectorStore: VectorStore initialized from documents and embeddings.\u001b[39;00m\n\u001b[0;32m    840\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 841\u001b[0m     texts \u001b[38;5;241m=\u001b[39m [\u001b[43md\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpage_content\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m documents]\n\u001b[0;32m    842\u001b[0m     metadatas \u001b[38;5;241m=\u001b[39m [d\u001b[38;5;241m.\u001b[39mmetadata \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m documents]\n\u001b[0;32m    844\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mids\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m kwargs:\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'str' object has no attribute 'page_content'"
     ]
    }
   ],
   "source": [
    "vectorstoredb=FAISS.from_documents(documents,res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hello",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
